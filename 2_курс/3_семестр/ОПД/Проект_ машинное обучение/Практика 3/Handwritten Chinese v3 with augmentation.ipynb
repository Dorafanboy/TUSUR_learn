{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Handwritten Chinese v3 with augmentation.ipynb","provenance":[{"file_id":"1vMV1HCKJiHNQGT6-riiBnWehNCI4X8gz","timestamp":1637073019200},{"file_id":"1ZZIc47jwBrdkxlcSjD8WXgcDCZh7noWB","timestamp":1634206187973},{"file_id":"159FVW-wN-JFLMa-r4T-Q_RRsECUUIqaR","timestamp":1605617213404},{"file_id":"https://github.com/AI-FREE-Team/Traditional-Chinese-Handwriting-Dataset/blob/master/Data_Deployment_colab.ipynb","timestamp":1605604630463}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"-HlCG5i4kDnS"},"source":["import numpy as np\n","import time\n","import PIL.Image as Image\n","import matplotlib.pylab as plt\n","import tensorflow as tf\n","import os\n","import zipfile\n","import shutil\n","\n","\n","!git clone https://github.com/AI-FREE-Team/Traditional-Chinese-Handwriting-Dataset.git\n","OutputFolder = '/content/Handwritten_Data'\n","!rm -rf '/content/Handwritten_Data'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tIMzxCtACUxL"},"source":["SIZE = 150 # рассматриваем 150 классов"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NEsfKRwc_bg0"},"source":["CompressedFiles = []\n","\n","os.chdir('/content/Traditional-Chinese-Handwriting-Dataset/data')\n","\n","for item in os.listdir():  \n","  if item.endswith('.zip'): # Check for \".zip\" extension.\n","    file_path = os.path.abspath(item) # Get full path of the compressed file. \n","    CompressedFiles.append(file_path)\n","\n","for file in CompressedFiles:     \n","  # Construct a ZipFile object with the filename, and then extract it.\n","  zip_ref = zipfile.ZipFile(file).extractall(OutputFolder) \n","  \n","  source_path = OutputFolder + '/cleaned_data(50_50)'\n","  img_list = os.listdir(source_path)\n","\n","  for img in img_list:\n","      shutil.move(source_path + '/' + img, OutputFolder) # Move a file to another location. \n","  \n","  shutil.rmtree(OutputFolder + '/cleaned_data(50_50)') \n","  #print(f'Decompress successfully {file} ......')\n","  #print( 'Moving images according to traditional Chinese characters......' )\n","\n","ImageList = os.listdir(OutputFolder)\n","ImageList = [img for img in ImageList if len(img)>1]\n","WordList = list(set([w.split('_')[0] for w in ImageList]))[:SIZE]\n","\n","for w in WordList:\n","  try:\n","    os.chdir(OutputFolder) # Change the current working directory to OutputPath.\n","    os.mkdir(w) # Create the new word folder in OutputPath.\n","    MoveList = [img for img in ImageList if w in img]\n","                \n","  except: \n","    os.chdir(OutputFolder)\n","    MoveList = [img for img in ImageList if w in img ]\n","  \n","  finally:            \n","    for img in MoveList:\n","      old_path = OutputFolder + '/' + img\n","      new_path = OutputFolder + '/' + w + '/' + img\n","      shutil.move( old_path, new_path )\n","\n","print( 'Data Deployment completed.' )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtJidZSSed2C"},"source":["a=0\n","b=0\n","\n","for item in os.listdir(OutputFolder):\n","  if (os.path.isdir(item)):  \n","    a += 1\n","    for i in os.listdir(OutputFolder + '/' + item):\n","      b +=1\n","\n","#print ('Всего: ' + str(a) + ' слов (папка) / Всего: ' + str(b) + ' образцов')\n","#print ('В среднем каждое слово содержит: ' + str (b / a) + ' образцов')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8BZsXzH5dSZA"},"source":["image_generator = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=0.1)\n","train_dataset = image_generator.flow_from_directory(str(OutputFolder), class_mode='sparse', batch_size=10, target_size=(50, 50), subset='training')\n","valid_dataset = image_generator.flow_from_directory(str(OutputFolder), class_mode='sparse', batch_size=10, target_size=(50, 50), subset='validation')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Sodcd863Adst"},"source":["data_augmentation = tf.keras.Sequential([\n","  tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n","  tf.keras.layers.RandomRotation(0.2),\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EGnVs1JIdcD"},"source":["IMG_SIZE = 40\n","\n","resize_and_rescale = tf.keras.Sequential([\n","  tf.keras.layers.Resizing(IMG_SIZE, IMG_SIZE),\n","  tf.keras.layers.Rescaling(1./255)\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5yTllMEdfrp"},"source":["for image_b, label_b in train_dataset:\n","  #print(\"Image batch shape: \", image_b.shape)\n","  #print(\"Label batch shape: \", label_b.shape)\n","  plt.imshow(image_b[1])\n","  image_batch = resize_and_rescale(image_b)\n","  \n","  label_batch = label_b\n","  #print(label_batch)\n","  break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"etnfw23vswSZ"},"source":["plt.imshow(image_batch[1])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WucSLXxZdpuc"},"source":["model = tf.keras.Sequential([\n","  tf.keras.layers.Conv2D(filters=16,  kernel_size=3, activation='relu', padding= 'same' , input_shape=(50,50,3)),\n","  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n","  tf.keras.layers.Conv2D(filters=32,  kernel_size=3, activation='relu', padding= 'same'),\n","  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n","  tf.keras.layers.Conv2D(filters=64,  kernel_size=3, activation='relu', padding= 'same'),\n","  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n","  tf.keras.layers.Conv2D(filters=128,  kernel_size=2, activation='relu', padding= 'same'),\n","  tf.keras.layers.MaxPooling2D(pool_size=(2,2), strides=2),\n","  tf.keras.layers.Conv2D(filters=256,  kernel_size=2, activation='relu', padding= 'same'),\n","  tf.keras.layers.Flatten(),\n","  tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","  #tf.keras.layers.Dropout(0.4),\n","  tf.keras.layers.Dense(SIZE, activation='softmax')\n","])\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FKYthET16Sez"},"source":["lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(1.8, decay_steps = 705*5, decay_rate = 0.1, staircase = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWAuDixXdzYa"},"source":["model.compile(\n","  optimizer=tf.keras.optimizers.Adadelta(lr_schedule),\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","  metrics=['accuracy']\n",")\n","EPOCHS = 20\n","history = model.fit(train_dataset,\n","                    validation_data=valid_dataset,\n","                    epochs=EPOCHS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XY8w5Bk0duJZ"},"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.figure(figsize=(10, 10))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([min(plt.ylim()),1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([min(plt.ylim()),max(plt.ylim())])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ezwGTtAzlYpx"},"source":["lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(0.5, decay_steps = 705*5, decay_rate = 0.1, staircase = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4a_q-GS5lYqW"},"source":["model.compile(\n","  optimizer=tf.keras.optimizers.Adadelta(lr_schedule),\n","  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","  metrics=['accuracy']\n",")\n","EPOCHS = 20\n","history = model.fit(train_dataset,\n","                    validation_data=valid_dataset,\n","                    epochs=EPOCHS)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vYrf7Uw_liBj"},"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.figure(figsize=(10, 10))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='Training Accuracy')\n","plt.plot(val_acc, label='Validation Accuracy')\n","plt.legend(loc='lower right')\n","plt.ylabel('Accuracy')\n","plt.ylim([min(plt.ylim()),1])\n","plt.title('Training and Validation Accuracy')\n","\n","plt.subplot(2, 1, 2)\n","plt.plot(loss, label='Training Loss')\n","plt.plot(val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.ylabel('Cross Entropy')\n","plt.ylim([min(plt.ylim()),max(plt.ylim())])\n","plt.title('Training and Validation Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"execution_count":null,"outputs":[]}]}